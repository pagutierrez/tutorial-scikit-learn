{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este breve tutorial explica algunos de los conceptos relacionados con la librería `scikit-learn` de python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python es un lenguaje de programación interpretado.\n",
    "- Su nombre proviene de la afición de su creador original, [Guido van Rossum](https://es.wikipedia.org/wiki/Guido_van_Rossum), por los humoristas británicos [Monty Python](https://es.wikipedia.org/wiki/Monty_Python).\n",
    "- Características:\n",
    "  - Programación orientada a objetos\n",
    "  - Programación imperativa\n",
    "  - Programación funcional.\n",
    "  - Es multiplataforma y posee una licencia abierta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entornos de desarrollo para python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entornos de desarrollo para Python\n",
    "  - [Sublime Text](http://www.sublimetext.com/)\n",
    "  - [PyCharm](https://www.jetbrains.com/pycharm/)\n",
    "  - [Spyder](https://github.com/spyder-ide/spyder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Librería que proporciona un amplio conjunto de algoritmos de aprendizaje supervisado y no supervisado a través de una consistente interfaz en `python`.\n",
    "- Publicado bajo licencia BSD y distribuido en muchos sistemas Linux, favorece el uso comercial y educacional.\n",
    "- Esta librería se ha construido sobre [`SciPy`](http://www.scipy.org/) (*Scientific Python*), que debe ser instalada antes de utilizarse, incluyendo:\n",
    "  - [**NumPy**](http://www.numpy.org/)\n",
    "  - [**Matplotlib**](http://matplotlib.org/)\n",
    "  - [SymPy](https://simpy.readthedocs.org/en/latest/)\n",
    "  - [**Pandas**](http://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Características de `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta librería se centra en el modelado de datos y no en cargar y manipular los datos, para lo que utilizaríamos [NumPy](http://www.numpy.org/) y [Pandas](http://pandas.pydata.org/). Algunas cosas que podemos hacer con `scikit-learn` son:\n",
    "  - *Clustering*.\n",
    "  - Validación cruzada.\n",
    "  - *Datasets* de prueba.\n",
    "  - Reducción de la dimensionalidad.\n",
    "  - *Ensemble methods*.\n",
    "  - *Feature selection*.\n",
    "  - *Parameter tuning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las principales ventajas de `scikit-learn` son las siguientes:\n",
    "  - Interfaz consistente ante modelos de aprendizaje automático.\n",
    "  - Proporciona muchos parámetros de configuración.\n",
    "  - Documentación excepcional.\n",
    "  - Desarrollo muy activo.\n",
    "  - Comunidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos de uso con el *dataset* `iris`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar un ejemplo típico en *machine learning* que es la base de datos `iris`.  En esta base de datos hay tres clases a predecir, que son tres especies distintas de la flor iris, de manera que, para cada flor, se extraen cuatro medidas o variables de entrada (longitud y ancho de los pétalos y los sépalos, en cm). Las tres especies a distinguir son iris *setosa*, iris *virginica* e iris *versicolor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya hemos comentado, para la lectura de datos haremos uso de [Pandas](http://pandas.pydata.org/). Esta librería tiene un método `read_csv` que nos va a permitir leer los datos desde un fichero de texto `csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Con estas líneas, importamos la funcionalidad necesaria para el ejemplo. `pandas` nos permitirá leer los datos, `numpy` nos va a permitir trabajar con ellos de forma matricial, `matplotlib` nos permite hacer representaciones gráficas y, de la librería `scikit-learn`, en este caso, utilizaremos un método de clasificación basado en los vecinos más cercanos y algunas funciones de preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `read_csv` de `pandas` permite dos modos de trabajo: que el propio fichero csv tenga una fila con los nombres de las variables o que nosotros especifiquemos los nombres de las variables en la llamada. En este caso, vamos a utilizar la segunda aproximación. De esta forma, creamos un *array* con los nombres de las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nombre_variables = ['longitud_sepalo', 'ancho_sepalo', 'longitud_petalo', 'ancho_petalo', 'clase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y leemos el dataset con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('data/iris.csv', names = nombre_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iris` es un objeto de la clase [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) de `pandas`. También podríamos haber obviado el nombre de las columnas estableciendo `header=None`, de forma que `read_csv` le hubiera asignado un nombre por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de nada, es conveniente realizar una pequeña **inspección** de los datos. Si simplemente queremos ver la cabecera del dataset, podemos utilizar el método `head(n)`, que devuelve un DataFrame incluyendo los primeros `n` patrones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.head(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a utilizar una función para inspeccionar detenidamente cada par de variables y su relación con las etiquetas de clase. De esta forma, construiremos un gráfico de (3x4) subgráficos que incluya, para cada par de variables, los 150 patrones, con un color que indique la etiqueta de clase y donde las coordenadas x e y se correspondan con los valores de las variables afectadas. Esto se puede hacer con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_dataset(dataset,nombre_variables):\n",
    "    \"\"\" Función que pinta un dataset\n",
    "    dataset es el DataFrame que vamos a utilizar para extraer los datos\n",
    "    nombre_variables es el nombre de las variables de ese dataset\n",
    "    * Supondremos que la última variable es la etiqueta de clase\n",
    "    \"\"\"\n",
    "    # Numero de variables\n",
    "    num_variables = dataset.shape[1]\n",
    "    # Extraer la etiqueta de clase\n",
    "    labels = dataset[nombre_variables[-1]]\n",
    "    # Convertir la etiqueta a números enteros (1,2,3...)\n",
    "    labelencoder = preprocessing.LabelEncoder()\n",
    "    labelencoder.fit(labels)\n",
    "    labels = labelencoder.transform(labels)\n",
    "    # Número de plot\n",
    "    plot_index = 1\n",
    "    plt.figure(figsize=(18,12))\n",
    "    plt.clf()\n",
    "    for i in range(0,num_variables-1):\n",
    "        for j in range(0,num_variables-1):\n",
    "            if i != j:  \n",
    "                # Extraer variables i y j\n",
    "                x = dataset[nombre_variables[i]]\n",
    "                y = dataset[nombre_variables[j]]\n",
    "                # Elegir el subplot\n",
    "                plt.subplot(num_variables-2, num_variables-1, plot_index)\n",
    "                # Pintar los puntos\n",
    "                plt.scatter(x, y, c=labels)\n",
    "                # Etiquetas para los ejes\n",
    "                plt.xlabel(nombre_variables[i])\n",
    "                plt.ylabel(nombre_variables[j])\n",
    "                # Título para el gráfico\n",
    "                plt.title(nombre_variables[j]+\" vs \"+nombre_variables[i])\n",
    "                # Extraer rangos de las variables y establecerlos\n",
    "                x_min, x_max = x.min() - .5, x.max() + .5\n",
    "                y_min, y_max = y.min() - .5, y.max() + .5\n",
    "                plt.xlim(x_min, x_max)\n",
    "                plt.ylim(y_min, y_max)\n",
    "                # Que no se vean los ticks\n",
    "                plt.xticks(())\n",
    "                plt.yticks(())\n",
    "                plot_index = plot_index + 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora queremos usar la función con el dataset iris, podemos llamarla de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(iris,nombre_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de objetos `DataFrame` y `ndarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) son objetos que representan a los *datasets* con los que vamos a operar. Permiten realizar muchas operaciones de forma automática, ayudando a transformar las variables de forma muy cómoda. Internamente, el dataset se guarda en un array bidimensional de `numpy` (clase [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)). El acceso a los elementos de un [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) es algo más simple si utilizamos su versión [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html), para lo cual simplemente tenemos que utilizar el atributo `values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['longitud_sepalo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris[nombre_variables[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array = iris.values\n",
    "print(iris_array[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sintaxis de indexación en un [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) es la siguiente:\n",
    "- `array[i,j]`: accede al valor de la fila `i` columna `j`.\n",
    "- `array[i:j,k]`: devuelve otro `ndarray` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y a la columna `k`.\n",
    "- `array[i:j,k:l]`: devuelve otro `ndarray` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y a las columnas desde la `k` hasta la `l`.\n",
    "- `array[i:j,:]`: devuelve otro `ndarray` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y **todas** las columnas.\n",
    "- `array[:,i:j]`: devuelve otro `ndarray` con la submatriz correspondiente a **todas** las filas y a las columnas desde la `k` hasta la `l`.\n",
    "De esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array[0:2,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[0:2][nombre_variables[2:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array[1:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[1:6][nombre_variables[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el acceso a través del `ndarray` es, por lo general, más cómodo, ya que no requerimos del nombre de las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `scikit-learn`, al igual que en otros lenguajes de programación como R o Matlab, debemos intentar, siempre que sea posible, *vectorizar* las operaciones. Esto es utilizar operaciones matriciales en lugar de bucles que recorran los arrays. La razón es que este tipo de operaciones están muchos más optimizadas y que el proceso de referenciación de *arrays* puede consumir mucho tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que queremos imprimir el área de sépalo de todas las flores. Compara la diferencia entre hacerlo mediante un bucle `for` y mediante operaciones matriciales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un array con el área del sépalo (longitud*anchura), utilizando un for\n",
    "# Crear un array vacío\n",
    "areaSepaloArray = np.empty(iris_array.shape[0])\n",
    "for i in range(0,iris_array.shape[0]):\n",
    "    areaSepaloArray[i] = iris_array[i,0] * iris_array[i,1]\n",
    "print(areaSepaloArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un array con el área del sépalo (longitud*anchura), utilizando operaciones matriciales\n",
    "print(iris_array[:,0] * iris_array[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es más, los `ndarray` permiten aplicar operaciones lógicas, que devuelven otro `ndarray` con el resultado de realizar esas operaciones lógicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array[:,2] > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A su vez, este `ndarray` se puede usar para indexar el `ndarray` original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array[iris_array[:,2] > 5,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagina que ahora queremos imprimir la longitud de sépalo de aquellas flores cuya longitud de sépalo es mayor que 2. Compara la versión con `for` y la versión \"vectorizada\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir las longitudes de sépalo mayores que 2, utilizando un for\n",
    "iris_array = iris.values\n",
    "for i in range(0,iris_array.shape[0]):\n",
    "    valorSepalo = iris_array[i,0]\n",
    "    if valorSepalo > 2:\n",
    "        print(valorSepalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir las longitudes de sépalo mayores que 2, utilizando operaciones matriciales\n",
    "print(iris_array[ iris_array[:,0] > 2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar algunas funciones adicionales sobre objetos de tipo `ndarray`. Por ejemplo, las funciones [`numpy.mean`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html) y [`numpy.std`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html) nos sirven para calcular la media y la desviación típica, respectivamente, de los valores contenidos en el `ndarray` que se pasa como argumento.\n",
    "\n",
    "Por último, podemos realizar operaciones matriciales con los `ndarray` de forma muy simple y optimizada. La función [`numpy.dot`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) multiplica dos `ndarray`, siempre que sus dimensiones sean compatibles. La función [`numpy.transpose`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html) nos devuelve la traspuesta de la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 0], [0, 1]]\n",
    "b = [[4, 1], [2, 2]]\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(4).reshape((2,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: Prueba a imprimir la media y la desviación típica del área de aquellas flores que son de tipo *virginica*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque a veces nos proporcionan los datos ya divididos en los conjuntos de entrenamiento y test, conviene saber como podríamos realizar esta división. El siguiente código muestra una función que divide los datos de forma aleatoria, utilizando operaciones *vectorizadas*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dividir_ent_test(dataframe, porcentaje=0.6):\n",
    "    \"\"\" \n",
    "    Función que divide un dataframe aleatoriamente en entrenamiento y en test.\n",
    "    Recibe los siguientes argumentos:\n",
    "    - dataframe: DataFrame que vamos a utilizar para extraer los datos\n",
    "    - porcentaje: porcentaje de patrones en entrenamiento\n",
    "    Devuelve:\n",
    "    - train: DataFrame con los datos de entrenamiento\n",
    "    - test: DataFrame con los datos de test\n",
    "    \"\"\"\n",
    "    mascara = np.random.rand(len(dataframe)) < porcentaje\n",
    "    train = dataframe[mascara]\n",
    "    test = dataframe[~mascara]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_train, iris_test = dividir_ent_test(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos quedarnos con las columnas correspondientes a las variables de entrada (todas salvo la última) y la correspondiente a la variable de salida (en este caso, la última):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_iris = iris_train.values[:,0:-1]\n",
    "train_outputs_iris = iris_train.values[:,-1]\n",
    "test_inputs_iris = iris_test.values[:,0:-1]\n",
    "test_outputs_iris = iris_test.values[:,-1]\n",
    "print(train_inputs_iris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos proporcionan la base de datos completa para que hagamos nosotros las particiones, todas las clases y funciones del módulo [`sklearn.cross_validation`](http://scikit-learn.org/stable/modules/cross_validation.html) de `scikit-learn` nos pueden facilitar mucho la labor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labores de preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, `scikit-learn` no acepta cadenas como parámetros de las funciones, todo deben de ser números. Para ello, nos podemos valer del objeto [`sklearn.preprocessing.LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html), que nos transforma automáticamente las cadenas a números. La forma en que se utiliza es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_e = preprocessing.LabelEncoder()\n",
    "label_e.fit(train_outputs_iris)\n",
    "train_outputs_iris_encoded = label_e.transform(train_outputs_iris)\n",
    "test_outputs_iris_encoded = label_e.transform(test_outputs_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podéis observar, primero se crea el `LabelEncoder` y luego se \"entrena\" mediante el método `fit`. Para un `LabelEncoder`, \"entrenar\" el modelo es decidir el mapeo que vimos anteriormente, en este caso:\n",
    "- `Iris-setosa` -> 0\n",
    "- `Iris-versicolor` -> 1\n",
    "- `Iris-virginica` -> 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado, utilizando el método `transform` del `LabelEncoder`, podremos transformar cualquier `ndarray` que queramos (hubiéramos tenido un error si alguna de las etiquetas de test no estuviera en train). Esta estructura (método `fit` más método `transform` o `predict`) se repite en muchos de los objetos de `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchas más tareas de preprocesamiento que se pueden hacer en `scikit-learn`. Consulta el paquete [`sklearn.preprocessing`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear y evaluar un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a crear un modelo de clasificación y a obtener su matriz de confusión. Vamos a utilizar el clasificador [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), que clasifica cada patrón asignándole la clase mayoritaria según los `k` vecinos más cercanos al patrón a clasificar. Consulta siempre la documentación de cada objeto para ver los parámetros del algoritmo (en este caso, el parámetro decisivo es `n_neighbors`). Veamos como se realizaría el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(train_inputs_iris, train_outputs_iris_encoded)\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos el modelo entrenado. Este modelo es de tipo *lazy*, en el sentido de que no existen parámetros a ajustar durante el entrenamiento. Lo único que hacemos es acomodar las entradas en una serie de estructuras de datos que faciliten el cálculo de distancias a la hora de predecir la etiqueta de datos nuevos. Si ahora queremos predecir las etiquetas de test, podemos hacer uso del método `predict`, que aplica el modelo ya entrenado a datos nuevos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_test = knn.predict(test_inputs_iris)\n",
    "print(prediccion_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos saber cómo de buena ha sido la clasificación, todo modelo de clasificación o regresión en `scikit-learn` tiene un método `score` que nos devuelve la bondad del modelo con respecto a los valores esperados, a partir de las entradas suministradas. La medida por defecto utilizada en [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) es el porcentaje de patrones bien clasificados (CCR o *accuracy*). La función se utiliza de la siguiente forma (internamente, esta función llama a `predict`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision = knn.score(test_inputs_iris, test_outputs_iris_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para imprimir la matriz de confusión de unas predicciones, podemos utilizar la función [`sklearn.metrics.confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix), que nos va devolver la matriz ya formada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_outputs_iris_encoded, prediccion_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar los parámetros de un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagina que quieres configurar el número de vecinos más cercanos (`n_neighbors`), de forma que la precisión en entrenamiento. Lo podríamos hacer de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nn in range(1,15):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=nn)\n",
    "    knn.fit(train_inputs_iris, train_outputs_iris_encoded)\n",
    "    precisionTrain = knn.score(train_inputs_iris, train_outputs_iris_encoded)\n",
    "    precisionTest = knn.score(test_inputs_iris, test_outputs_iris_encoded)\n",
    "    print(\"%d vecinos: CCR train=%.2f%%, CCR test=%.2f%%\" % (nn, precisionTrain*100, precisionTest*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio voluntario a realizar\n",
    "\n",
    "Debes utilizar la base de datos `digits` para entrenar dos modelos supervisados de clasificación:\n",
    "- Uno basado en los k vecinos más cercanos: [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n",
    "- Otro basado en un modelo lineal. Vamos a utilizar el modelo de regresión logística: [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "La base de datos está disponible en la UCI, bajo el nombre [*Optical Recognition of Handwritten Digits Data Set*](http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits). Bájala y preprocésala para realizar el entrenamiento. Utiliza las particiones de entrenamiento y test incluidas en el sitio web de la UCI. Tienes que normalizar todas las variables de entrada para que queden en el intervalo `[0,1]` (consulta información sobre [MinMaxScaler](http://scikit-learn.org/stable/modules/preprocessing.html#scaling-features-to-a-range)). Intenta ajustar lo mejor posibles los parámetros de los clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "Este tutorial se ha basado en gran parte en el siguiente material:\n",
    "- Python como alternativa a R en *machine learning*. Mario Pérez Esteso. [Enlace a Github](https://github.com/MarioPerezEsteso/Python-Machine-Learning). [Enlace a Youtube](https://www.youtube.com/watch?v=8yz4gWt7Klk). \n",
    "\n",
    "Se recomiendan los siguientes tutoriales adicionales para aprender más sobre el manejo de la librería:\n",
    "- *An introduction to machine learning with scikit-learn*. Documentación oficial de `scikit-learn`. [http://scikit-learn.org/stable/tutorial/basic/tutorial.html](http://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n",
    "- *A tutorial on statistical-learning for scientific data processing*. Documentación oficial de `scikit-learn`. [http://scikit-learn.org/stable/tutorial/statistical_inference/index.html](http://scikit-learn.org/stable/tutorial/statistical_inference/index.html).\n",
    "\n",
    "Por último, para aprender la sintaxis básica de Python en menos de 13 horas, se recomienda el siguiente curso de *CodeAcademy*:\n",
    "- Curso de Python de CodeAcademy. [https://www.codecademy.com/es/learn/python](https://www.codecademy.com/es/learn/python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
