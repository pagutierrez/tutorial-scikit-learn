{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este breve tutorial explica algunos de los conceptos relacionados con la librería `scikit-learn` de python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python es un lenguaje de programación interpretado.\n",
    "- Su nombre proviene de la afición de su creador original, [Guido van Rossum](https://es.wikipedia.org/wiki/Guido_van_Rossum), por los humoristas británicos [Monty Python](https://es.wikipedia.org/wiki/Monty_Python).\n",
    "- Características:\n",
    "  - Programación orientada a objetos\n",
    "  - Programación imperativa\n",
    "  - Programación funcional.\n",
    "  - Es multiplataforma y posee una licencia abierta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entornos de desarrollo para python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entornos de desarrollo para Python\n",
    "  - [Sublime Text](http://www.sublimetext.com/)\n",
    "  - [PyCharm](https://www.jetbrains.com/pycharm/)\n",
    "  - [Spyder](https://github.com/spyder-ide/spyder)\n",
    "  - [Visual Studio Code](https://code.visualstudio.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Librería que proporciona un amplio conjunto de algoritmos de aprendizaje supervisado y no supervisado a través de una consistente interfaz en `python`.\n",
    "- Publicado bajo licencia BSD y distribuido en muchos sistemas Linux, favorece el uso comercial y educacional.\n",
    "- Esta librería se ha construido sobre [`SciPy`](http://www.scipy.org/) (*Scientific Python*), que debe ser instalada antes de utilizarse, incluyendo:\n",
    "  - [**NumPy**](http://www.numpy.org/)\n",
    "  - [**Matplotlib**](http://matplotlib.org/)\n",
    "  - [SymPy](https://simpy.readthedocs.org/en/latest/)\n",
    "  - [**Pandas**](http://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Características de `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta librería se centra en el modelado de datos y no en cargar y manipular los datos, para lo que utilizaríamos [NumPy](http://www.numpy.org/) y [Pandas](http://pandas.pydata.org/). Algunas cosas que podemos hacer con `scikit-learn` son:\n",
    "  - *Clustering*.\n",
    "  - Validación cruzada.\n",
    "  - *Datasets* de prueba.\n",
    "  - Reducción de la dimensionalidad.\n",
    "  - *Ensemble methods*.\n",
    "  - *Feature selection*.\n",
    "  - *Parameter tuning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las principales ventajas de `scikit-learn` son las siguientes:\n",
    "  - Interfaz consistente ante modelos de aprendizaje automático.\n",
    "  - Proporciona muchos parámetros de configuración.\n",
    "  - Documentación excepcional.\n",
    "  - Desarrollo muy activo.\n",
    "  - Comunidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks (libros de notas o cuadernos Jupyter)\n",
    "==================\n",
    "\n",
    "* Puedes ejecutar un `Cell` (celda) pulsando ``[shift] + [Enter]`` o presionando el botón `Play` en la barra de herramientas.\n",
    "\n",
    "![](images/ipython_run_cell.png)\n",
    "\n",
    "* Puedes obtener ayuda sobre una función u objeto presionando ``[shift] + [tab]`` después de los paréntesis de apertura ``function(``\n",
    "\n",
    "![](images/ipython_help-1.png)\n",
    "\n",
    "* También puedes obtener la ayuda ejecutando ``function?``\n",
    "\n",
    "![](images/ipython_help-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas líneas, importamos la funcionalidad necesaria para el ejemplo. `pandas` nos permitirá leer los datos, `numpy` nos va a permitir trabajar con ellos de forma matricial, `matplotlib` nos permite hacer representaciones gráficas y, de la librería `scikit-learn`, en este caso, utilizaremos un método de clasificación basado en los vecinos más cercanos y algunas funciones de preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una parte muy importante del aprendizaje automático es la visualización de datos. La herramienta más habitual para esto en Python es [`matplotlib`](http://matplotlib.org). Es un paquete extremadamente flexible y ahora veremos algunos elementos básicos.\n",
    "\n",
    "Ya que estamos usando los libros (*notebooks*) Jupyter, vamos a usar una de las [funciones mágicas](https://ipython.org/ipython-doc/3/interactive/magics.html) que vienen incluidas en IPython, el modo \"*matoplotlib inline*\", que dibujará los *plots* directamente en el libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar una línea\n",
    "x = np.linspace(0, 10, 100)\n",
    "plt.plot(x, np.sin(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Python, por norma general, no es necesario utilizar ';' al finalizar cada sentencia, no obstante al dibujar *inline* una gráfica podemos usar ';' para evitar la salida real de *matplotlib* y que se muestre solamente la figura.\n",
    "Prueba a ejecutar la la caja anterior quitando el ';' a la última sentencia. ¿Qué diferencia aprecias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujar un scatter (dispersión)\n",
    "x = np.random.normal(size=500)\n",
    "y = np.random.normal(size=500)\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar imágenes usando imshow\n",
    "# - Tener en cuenta que el origen por defecto está arriba a la izquierda\n",
    "\n",
    "x = np.linspace(1, 12, 100)\n",
    "y = x[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método de numpy *np.newaxis* crea un nuevo eje. Prueba a imprimir la dimensión de `x` e `y` usando el método de numpy `.shape`, ¿ves la diferencia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = y * np.sin(x) * np.cos(y)\n",
    "print(im.shape)\n",
    "\n",
    "plt.imshow(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué estamos viendo en esta imagen?\n",
    "\n",
    "No es más que un corte transversal del cruce de la función seno y la función coseno.\n",
    "\n",
    "Si tienes dudas, siempre puedes [preguntarle a Google](https://www.google.es/search?dcr=0&ei=cGr8WbKFNsmTa_b1n6AI&q=sin%28x%29*cos%28y%29+from+-6+to+6&oq=sin%28x%29*cos%28y%29+from+-6+to+6&gs_l=psy-ab.3...5574.8328.0.8486.6.5.1.0.0.0.79.355.5.5.0....0...1.1.64.psy-ab..0.0.0....0.3Kq-XpUPDRs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer un diagrama de curvas de nivel (contour plot)\n",
    "# - El origen aquí está abajo a la izquierda\n",
    "plt.contour(im);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El modo \"notebook\" en lugar de inline permite que los plots sean interactivos\n",
    "#%matplotlib inline\n",
    "# Plot en 3D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "ax = plt.axes(projection='3d')\n",
    "xgrid, ygrid = np.meshgrid(x, y.ravel())\n",
    "ax.plot_surface(xgrid, ygrid, im, cmap=plt.cm.viridis, cstride=2, rstride=2, linewidth=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchísimos tipos de gráficos disponibles. Una forma útila de explorarlos es mirar la [galería de matplotlib](http://matplotlib.org/gallery.html).\n",
    "\n",
    "Prueba alguno de estos ejemplos. Por ejemplo, `https://matplotlib.org/mpl_examples/shapes_and_collections/path_patch_demo.py`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demo of a PathPatch object.\n",
    "\"\"\"\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "Path = mpath.Path\n",
    "path_data = [\n",
    "    (Path.MOVETO, (1.58, -2.57)),\n",
    "    (Path.CURVE4, (0.35, -1.1)),\n",
    "    (Path.CURVE4, (-1.75, 2.0)),\n",
    "    (Path.CURVE4, (0.375, 2.0)),\n",
    "    (Path.LINETO, (0.85, 1.15)),\n",
    "    (Path.CURVE4, (2.2, 3.2)),\n",
    "    (Path.CURVE4, (3, 0.05)),\n",
    "    (Path.CURVE4, (2.0, -0.5)),\n",
    "    (Path.CLOSEPOLY, (1.58, -2.57)),\n",
    "    ]\n",
    "codes, verts = zip(*path_data)\n",
    "path = mpath.Path(verts, codes)\n",
    "patch = mpatches.PathPatch(path, facecolor='r', alpha=0.5)\n",
    "ax.add_patch(patch)\n",
    "\n",
    "# plot control points and connecting lines\n",
    "x, y = zip(*path.vertices)\n",
    "line, = ax.plot(x, y, 'go-')\n",
    "\n",
    "ax.grid()\n",
    "ax.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos de uso con el *dataset* `iris`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar un ejemplo típico en *machine learning* que es la base de datos `iris`.  En esta base de datos hay tres clases a predecir, que son tres especies distintas de la flor iris, de manera que, para cada flor, se extraen cuatro medidas o variables de entrada (longitud y ancho de los pétalos y los sépalos, en cm). Las tres especies a distinguir son iris *setosa*, iris *virginica* e iris *versicolor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya hemos comentado, para la lectura de datos haremos uso de [Pandas](http://pandas.pydata.org/). Esta librería tiene un método `read_csv` que nos va a permitir leer los datos desde un fichero de texto `csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `read_csv` de `pandas` permite dos modos de trabajo: que el propio fichero csv tenga una fila con los nombres de las variables o que nosotros especifiquemos los nombres de las variables en la llamada. En este caso, vamos a utilizar la segunda aproximación. De esta forma, creamos un *array* con los nombres de las variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_variables = ['longitud_sepalo', 'ancho_sepalo', 'longitud_petalo', 'ancho_petalo', 'clase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y leemos el dataset con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/ayrna/tutorial-scikit-learn-IMC/master/data/iris.csv', names = nombre_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iris` es un objeto de la clase [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) de `pandas`. También podríamos haber obviado el nombre de las columnas estableciendo `header=None`, de forma que `read_csv` le hubiera asignado un nombre por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de nada, es conveniente realizar una pequeña **inspección** de los datos. Si simplemente queremos ver la cabecera del dataset, podemos utilizar el método `head(n)`, que devuelve un DataFrame incluyendo los primeros `n` patrones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.head(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos datos tienen cuatro dimensiones, pero podemos visualizar una o dos de las dimensiones usando un histograma o un scatter. Primero, activamos el *matplotlib inline mode*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_x = 3\n",
    "colors = ['blue', 'red', 'green']\n",
    "iris_target_names = np.unique(iris['clase'])\n",
    "\n",
    "for indice, color in zip(range(len(iris_target_names)), colors): #¿qué hace zip?\n",
    "    #Separamos el conjunto en las distintas clases\n",
    "    patrones = (iris['clase']==iris_target_names[indice]) #esta comparación la explicaremos más adelante\n",
    "    plt.hist(iris.values[patrones, variable_x], label=iris_target_names[indice], color=color)\n",
    "\n",
    "plt.xlabel(nombre_variables[variable_x])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que las variables de entrada eran *['longitud_sepalo', 'ancho_sepalo', 'longitud_petalo', 'ancho_petalo', 'clase']*, sabiendo esto, ¿qué debemos modificar  en el código superior para mostrar la longitud del sépalo? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a representar en un gráfico la relación entre dos variables de entrada, así podremos ver si los patrones tienen algunas características que nos ayuden a crear un modelo lineal. Prueba distintas combinaciones de variables que se representan en los ejes, para ello modifica los valores de *vairable_x* y *variable_y*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_x = 1 \n",
    "variable_y = 0\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for indice, color in zip(range(len(iris_target_names)), colors): #¿qué hace zip?\n",
    "    patrones = (iris['clase']==iris_target_names[indice])\n",
    "    plt.scatter(iris.values[patrones, variable_x], \n",
    "                iris.values[patrones, variable_y],\n",
    "                label=iris_target_names[indice],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(nombre_variables[variable_x])\n",
    "plt.ylabel(nombre_variables[variable_y])\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Has encontrado alguna combinación que haga que los datos sean linealmente separables?\n",
    "Es un poco tedioso probar todas las posibles combinaciones, ¡y eso que en este ejemplo tenemos pocas variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices scatterplot\n",
    "\n",
    "En lugar de realizar los plots por separado, una herramienta común que utilizan los analistas son las **matrices scatterplot**.\n",
    "\n",
    "Estas matrices muestran los scatter plots entre todas las características del dataset, así como los histogramas para ver la distribución de cada característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from pkg_resources import parse_version\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(iris['clase'])\n",
    "clases_numeros = le.transform(iris['clase'])\n",
    "\n",
    "iris_df = pd.DataFrame(iris[nombre_variables], columns=nombre_variables)\n",
    "\n",
    "#Para versiones de pandas>0.16 se debe llamar al método como pd.plotting.scatter_matrix\n",
    "if(parse_version(pd.__version__) > parse_version('0.16')):\n",
    "    pd.plotting.scatter_matrix(iris_df, c=clases_numeros, figsize=(8, 8));\n",
    "else:\n",
    "    pd.tools.plotting.scatter_matrix(iris_df, c=clases_numeros, figsize=(8, 8));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de objetos `DataFrame` y matrices numpy (`ndarray`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) son objetos que representan a los *datasets* con los que vamos a operar. Permiten realizar muchas operaciones de forma automática, ayudando a transformar las variables de forma muy cómoda. Internamente, el dataset se guarda en un array bidimensional de `numpy` (clase [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)). El acceso a los elementos de un [`DataFrame`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) es algo más simple si utilizamos su versión [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html), para lo cual simplemente tenemos que utilizar el atributo `values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['longitud_sepalo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris[nombre_variables[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array = iris.values\n",
    "print(iris_array[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sintaxis de indexación en un [`ndarray`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html) es la siguiente:\n",
    "- `array[i,j]`: accede al valor de la fila `i` columna `j`.\n",
    "- `array[i:j,k]`: devuelve otro `ndarray` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y a la columna `k`.\n",
    "- `array[i:j,k:l]`: devuelve otro `ndarray` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y a las columnas desde la `k` hasta la `l`.\n",
    "- `array[i:j,:]`: devuelve otro `ndarray` con la submatriz correspondiente a las filas desde la `i` hasta la `j-1` y **todas** las columnas.\n",
    "- `array[:,i:j]`: devuelve otro `ndarray` con la submatriz correspondiente a **todas** las filas y a las columnas desde la `k` hasta la `l`.\n",
    "De esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el array es menos bonito\n",
    "iris_array[0:2,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el \"pandas\" siempre es vistoso\n",
    "iris[0:2][nombre_variables[2:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array[1:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[1:6][nombre_variables[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el acceso a través del `ndarray` es, por lo general, más cómodo, ya que no requerimos del nombre de las variables. Ahora vamos a manejar una matriz de valores aleatorios, para ver algunas características adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Semilla de números aleatorios (para reproducibilidad)\n",
    "rnd = np.random.RandomState(seed=123)\n",
    "\n",
    "# Generar una matriz aleatoria\n",
    "X = rnd.uniform(low=0.0, high=1.0, size=(3, 5))  # dimensiones 3x5\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(tened en cuenta que los arrays en numpy se indexan desde el 0, al igual que la mayoría de estructuras en Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a los elementos\n",
    "\n",
    "# Obtener un único elemento\n",
    "# (primera fila, primera columna)\n",
    "print(X[0, 0])\n",
    "\n",
    "# Obtener una fila\n",
    "# (segunda fila)\n",
    "print(X[1])\n",
    "\n",
    "# Obtener una columna\n",
    "# (segunda columna)\n",
    "print(X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "    1 & 2 & 3 & 4 \\\\\n",
    "    5 & 6 & 7 & 8\n",
    "\\end{bmatrix}^T\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "    1 & 5 \\\\\n",
    "    2 & 6 \\\\\n",
    "    3 & 7 \\\\\n",
    "    4 & 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la traspuesta\n",
    "print(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un vector fila de números con la misma separación\n",
    "# sobre un intervalo prefijado\n",
    "y = np.linspace(start=0, stop=12, num=5)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar el vector fila en un vector columna\n",
    "print(y[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la forma de un array y cambiarla\n",
    "\n",
    "# Generar un array aleatorio\n",
    "rnd = np.random.RandomState(seed=123)\n",
    "X = rnd.uniform(low=0.0, high=1.0, size=(3, 5))  # a 3 x 5 array\n",
    "\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(X.reshape(5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexar según un conjunto de números enteros\n",
    "indices = np.array([3, 1, 0])\n",
    "print(indices)\n",
    "X[:, indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización de operaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `scikit-learn`, al igual que en otros lenguajes de programación como R o Matlab, debemos intentar, siempre que sea posible, *vectorizar* las operaciones. Esto es utilizar operaciones matriciales en lugar de bucles que recorran los arrays. La razón es que este tipo de operaciones están muchos más optimizadas y que el proceso de referenciación de *arrays* puede consumir mucho tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que queremos imprimir el área de sépalo de todas las flores. Compara la diferencia entre hacerlo mediante un bucle `for` y mediante operaciones matriciales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un array con el área del sépalo (longitud*anchura), utilizando un for:\n",
    "\n",
    "# Crear un array vacío\n",
    "areaSepaloArray = np.empty(iris_array.shape[0])\n",
    "\n",
    "# Bucle for \n",
    "for i in range(iris_array.shape[0]):\n",
    "    areaSepaloArray[i] = iris_array[i,0] * iris_array[i,1]\n",
    "    \n",
    "print(areaSepaloArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un array con el área del sépalo (longitud*anchura), utilizando operaciones matriciales\n",
    "areaSepaloArray_2 = iris_array[:,0] * iris_array[:,1]\n",
    "print (areaSepaloArray_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es más, los `ndarray` permiten aplicar operaciones lógicas, que devuelven otro `ndarray` con el resultado de realizar esas operaciones lógicas:\n",
    "¿Qué patrones tienen la longitud del pétalo (variable 2) mayor a 5 unidades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array[:,2] > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A su vez, este `ndarray` se puede usar para indexar el `ndarray` original:\n",
    "¿cuál es la clase de los patrones que tienen la longitud del pétalo mayor que 5 unidades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_array[iris_array[:,2] > 5,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagina que ahora queremos imprimir la longitud de sépalo de aquellas flores cuya longitud de sépalo es mayor que 2. Compara la versión con `for` y la versión \"vectorizada\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir las longitudes de sépalo mayores que 2, utilizando un for\n",
    "iris_array = iris.values\n",
    "for i in range(0,iris_array.shape[0]):\n",
    "    valorSepalo = iris_array[i,0]\n",
    "    if valorSepalo > 2:\n",
    "        print(valorSepalo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir las longitudes de sépalo mayores que 2, utilizando operaciones matriciales\n",
    "print(iris_array[ iris_array[:,0] > 2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar algunas funciones adicionales sobre objetos de tipo `ndarray`. Por ejemplo, las funciones [`numpy.mean`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html) y [`numpy.std`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html) nos sirven para calcular la media y la desviación típica, respectivamente, de los valores contenidos en el `ndarray` que se pasa como argumento.\n",
    "\n",
    "Por último, podemos realizar operaciones matriciales con los `ndarray` de forma muy simple y optimizada. La función [`numpy.dot`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) multiplica dos `ndarray`, siempre que sus dimensiones sean compatibles. La función [`numpy.transpose`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html) nos devuelve la traspuesta de la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 0], [0, 1]]\n",
    "b = [[4, 1], [2, 2]]\n",
    "\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(4).reshape((2,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: Prueba a imprimir la media y la desviación típica del área de sépalo aquellas flores que son de tipo *virginica*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División de datos en entrenamiento y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque a veces nos proporcionan los datos ya divididos en los conjuntos de entrenamiento y test, conviene saber como podríamos realizar esta división. El siguiente código muestra una función que divide los datos de forma aleatoria, utilizando operaciones *vectorizadas*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_ent_test(dataframe, porcentaje=0.6):\n",
    "    \"\"\" \n",
    "    Función que divide un dataframe aleatoriamente en entrenamiento y en test.\n",
    "    Recibe los siguientes argumentos:\n",
    "    - dataframe: DataFrame que vamos a utilizar para extraer los datos\n",
    "    - porcentaje: porcentaje de patrones en entrenamiento\n",
    "    Devuelve:\n",
    "    - train: DataFrame con los datos de entrenamiento\n",
    "    - test: DataFrame con los datos de test\n",
    "    \"\"\"\n",
    "    mascara = np.random.rand(len(dataframe)) < porcentaje\n",
    "    train = dataframe[mascara]\n",
    "    test = dataframe[~mascara] #¿para qué sirve ~?\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train, iris_test = dividir_ent_test(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos quedarnos con las columnas correspondientes a las variables de entrada (todas salvo la última) y la correspondiente a la variable de salida (en este caso, la última):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_iris = iris_train.values[:,0:-1]\n",
    "train_outputs_iris = iris_train.values[:,-1]\n",
    "\n",
    "test_inputs_iris = iris_test.values[:,0:-1]\n",
    "test_outputs_iris = iris_test.values[:,-1]\n",
    "\n",
    "print(train_inputs_iris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos proporcionan la base de datos completa para que hagamos nosotros las particiones, todas las clases y funciones del módulo [`sklearn.model_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) de `scikit-learn` nos pueden facilitar mucho la labor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "inputs_iris = iris.values[:,0:-1]\n",
    "outputs_iris = iris.values[:,-1]\n",
    "\n",
    "train_inputs_iris, test_inputs_iris, train_outputs_iris, test_outputs_iris = \\\n",
    "       train_test_split(inputs_iris, outputs_iris, test_size=0.33, random_state=42, stratify=outputs_iris)\n",
    "\n",
    "print(train_inputs_iris.shape)\n",
    "print(test_inputs_iris.shape)\n",
    "print([sum(train_outputs_iris==etiqueta)/train_outputs_iris.shape[0] for etiqueta in np.unique(outputs_iris)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labores de preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, `scikit-learn` no acepta cadenas como parámetros de las funciones, todo deben de ser números. Para ello, nos podemos valer del objeto [`sklearn.preprocessing.LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html), que nos transforma automáticamente las cadenas a números. La forma en que se utiliza es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación del método\n",
    "label_e = preprocessing.LabelEncoder()\n",
    "\n",
    "#Entrenamiento del método\n",
    "label_e.fit(train_outputs_iris)\n",
    "\n",
    "#Obtención de salidas\n",
    "train_outputs_iris_encoded = label_e.transform(train_outputs_iris)\n",
    "test_outputs_iris_encoded = label_e.transform(test_outputs_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podéis observar, primero se crea el `LabelEncoder` y luego se \"entrena\" mediante el método `fit`. Para un `LabelEncoder`, \"entrenar\" el modelo es decidir el mapeo que vimos anteriormente, en este caso:\n",
    "- `Iris-setosa` -> 0\n",
    "- `Iris-versicolor` -> 1\n",
    "- `Iris-virginica` -> 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado, utilizando el método `transform` del `LabelEncoder`, podremos transformar cualquier `ndarray` que queramos (hubiéramos tenido un error si alguna de las etiquetas de test no estuviera en train). Esta estructura (método `fit` más método `transform` o `predict`) se repite en muchos de los objetos de `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchas más tareas de preprocesamiento que se pueden hacer en `scikit-learn`. Consulta el paquete [`sklearn.preprocessing`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear y evaluar un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a crear un modelo de clasificación y a obtener su matriz de confusión. Vamos a utilizar el clasificador [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), que clasifica cada patrón asignándole la clase mayoritaria según los `k` vecinos más cercanos al patrón a clasificar. Consulta siempre la documentación de cada objeto para ver los parámetros del algoritmo (en este caso, el parámetro decisivo es `n_neighbors`). Veamos como se realizaría el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(train_inputs_iris, train_outputs_iris_encoded)\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos el modelo entrenado. Este modelo es de tipo *lazy*, en el sentido de que no existen parámetros a ajustar durante el entrenamiento. Lo único que hacemos es acomodar las entradas en una serie de estructuras de datos que faciliten el cálculo de distancias a la hora de predecir la etiqueta de datos nuevos. Si ahora queremos predecir las etiquetas de test, podemos hacer uso del método `predict`, que aplica el modelo ya entrenado a datos nuevos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_test = knn.predict(test_inputs_iris)\n",
    "print(prediccion_test)\n",
    "print(test_outputs_iris_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos saber cómo de buena ha sido la clasificación, todo modelo de clasificación o regresión en `scikit-learn` tiene un método `score` que nos devuelve la bondad del modelo con respecto a los valores esperados, a partir de las entradas suministradas. La medida por defecto utilizada en [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) es el porcentaje de patrones bien clasificados (CCR o *accuracy*). La función se utiliza de la siguiente forma (internamente, esta función llama a `predict`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = knn.score(test_inputs_iris, test_outputs_iris_encoded)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto sería similar a hacer la comparación a mano y calcular la media:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(prediccion_test == test_outputs_iris_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para imprimir la matriz de confusión de unas predicciones, podemos utilizar la función [`sklearn.metrics.confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix), que nos va devolver la matriz ya formada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_outputs_iris_encoded, prediccion_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar los parámetros de un clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagina que quieres configurar el número de vecinos más cercanos (`n_neighbors`), de forma que la precisión en entrenamiento sea lo más alta posible. Lo podríamos hacer de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nn in range(1,15):\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=nn)\n",
    "    knn.fit(train_inputs_iris, train_outputs_iris_encoded)\n",
    "    precisionTrain = knn.score(train_inputs_iris, train_outputs_iris_encoded)\n",
    "    precisionTest = knn.score(test_inputs_iris, test_outputs_iris_encoded)\n",
    "    print(\"%d vecinos: \\tCCR train = %.2f%%, \\tCCR test = %.2f%%\" % (nn, precisionTrain*100, precisionTest*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio propuesto para realizar\n",
    "\n",
    "Debes utilizar la base de datos `german` para entrenar dos modelos supervisados de clasificación:\n",
    "- Uno basado en los k vecinos más cercanos: [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n",
    "- Otro basado en un modelo lineal. Vamos a utilizar el modelo de regresión logística: [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "La base de datos está disponible en la UCI, bajo el nombre [*Statlog (German Credit Data) Data Set*](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29). Bájala y preprocésala para realizar el entrenamiento (utiliza la versión numérica, `german.data-numeric`, observa que los datos no tienen cabecera y utiliza el método `read_csv` de `pandas` especificando correctamente el separador, que en este caso es el uno o más espacios, es decir, `'\\s+'`). Divide los datos en 60% de entrenamiento y 40% de test (utiliza la función [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)). Tienes que normalizar todas las variables de entrada para que queden en el intervalo `[0,1]` (consulta información sobre [MinMaxScaler](http://scikit-learn.org/stable/modules/preprocessing.html#scaling-features-to-a-range)). Intenta ajustar lo mejor posibles los parámetros de los clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "Este tutorial se ha basado en gran parte en el siguiente material:\n",
    "- Python como alternativa a R en *machine learning*. Mario Pérez Esteso. [Enlace a Github](https://github.com/MarioPerezEsteso/Python-Machine-Learning). [Enlace a Youtube](https://www.youtube.com/watch?v=8yz4gWt7Klk). \n",
    "- Tutorial de Alex Gramfort y Andreas Mueller [[Github]](https://github.com/amueller/scipy-2017-sklearn)[[Youtube1]](https://www.youtube.com/watch?v=2kT6QOVSgSg)[[Youtube2]](https://www.youtube.com/watch?v=WLYzSas511I)\n",
    "\n",
    "Se recomiendan los siguientes tutoriales adicionales para aprender más sobre el manejo de la librería:\n",
    "- *An introduction to machine learning with scikit-learn*. Documentación oficial de `scikit-learn`. [http://scikit-learn.org/stable/tutorial/basic/tutorial.html](http://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n",
    "- *A tutorial on statistical-learning for scientific data processing*. Documentación oficial de `scikit-learn`. [http://scikit-learn.org/stable/tutorial/statistical_inference/index.html](http://scikit-learn.org/stable/tutorial/statistical_inference/index.html).\n",
    "\n",
    "Por último, para aprender la sintaxis básica de Python en menos de 13 horas, se recomienda el siguiente curso de *CodeAcademy*:\n",
    "- Curso de Python de CodeAcademy. [https://www.codecademy.com/es/learn/python](https://www.codecademy.com/es/learn/python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
